高效赋能AIoT生态链：

本教程以飞凌嵌入式[RK3399](https://so.csdn.net/so/search?q=RK3399&spm=1001.2101.3001.7020)平台为例，讲述主动模式和被动模式的人工智能计算棒部署流程。

![](https://i-blog.csdnimg.cn/blog_migrate/c558f62cb004c3cc689aa9ff9eabdb9f.png)

## 硬件平台

> 平台：OK3399-C开发板  
> 系统：Desktop  
> 模块：TB-RK1808S0  
> 环境准备： 飞凌OK3399-C开发板，RK1808人工智能计算棒（固件版本为V1.3.4），usb摄像头，摄像头和计算棒都插入OK3399-C开发板。

使用lsusb命令查看，如下（红框部分2207:0018即为RK1808人工智能计算棒）：

输入命令如下：

![](https://i-blog.csdnimg.cn/blog_migrate/d69710a84bf0e67bf096424f7df94b8f.png)

注意：因为被动模式需要安装的库文件较多，占用空间较大，所以需要扩大rootfs分区，修改param/parameter.txt文件0x00f00000@0x0005a000(rootfs) //0x f00000个块（512字节）=7.5G

改为

0x01800000@0x0005a000(rootfs) //0x1800000个块=12G

修改后进入系统，查看分区大小：

![](https://i-blog.csdnimg.cn/blog_migrate/e4a39e161992809b7b0731fe18f676c0.png)

## 概述

AI计算区分为四个不同的象限，分别是云端训练、云端推理，边缘训练以及边缘推理。其中终端推理，几乎都集中在[Arm架构](https://so.csdn.net/so/search?q=Arm%E6%9E%B6%E6%9E%84&spm=1001.2101.3001.7020)生态上。AI神经网络计算目前可以通过CPU、GPU、DSP、NPU、FAGA等完成，但不同的硬件特性会导致效率和功耗的不同。其中NPU——嵌入式神经网络处理器采用“数据驱动并行计算”的架构，最擅长的就是视频、图像类的海量多媒体数据的处理，并且相比GPU等具有更低的功耗。我司推出OK3399-CDesktop+RK1808（含3Tops算力NPU）的组合，在满足AI边缘计算的情况下，使得功耗大幅降低。

RK1808人工智能计算棒是一个专用AI应用模块，拥有主动模式和被动模式两种模式。

主动模式下：RK1808人工智能计算棒作为主动设备，RK1808人工智能计算棒内部默认已安装rknn-toolkit和rknn-api，上位机（也称宿主机）无需安装rknn-toolkit和rknn-api，模型及算法固化在RK1808人工智能计算棒中，OK3399-C通过USB口向计算棒输入数据（例如图片和视频流），RK1808人工智能计算棒自动完成数据的前处理、推理、后处理，然后把处理结果通过USB口输出给OK3399-C。

为了方便用户通过USB口传输数据，RK1808人工智能计算棒会把USB口虚拟成网卡等标准设备，用户只需通过标准设备接口的操作（例如网络的socket编程）即可完成对RK1808人工智能计算棒数据的输入和输出。

被动模式下：OK3399-C通过RKNN-Toolkit将模型及前处理后的数据传输给RK1808人工智能计算棒，RK1808人工智能计算棒完成推理，并把结果返回OK3399-C，OK3399-C进行后处理以及显示等操作。

## 主动模式

#### 细节如下：

1. RK1808计算棒插入上位机后，会被虚拟成网卡设备;

2. 上位机OK3399-C进行虚拟网卡配置，配置IP为192.168.180.1，保证上位机和1808中间的网络连接正常；

3. 计算棒默认IP为192.168.180.8，账号密码皆为toybrick，用户可以SSH登录计算棒，拷贝模型和server服务程序到计算棒；

4. 计算棒端运行server服务程序，用来接收上位机的连接请求，并调用RKNN进行处理，再返回结果；

5. 上位机运行client程序，连接server成功之后，发送推理请求，从1808端获取返回结果。

![](https://i-blog.csdnimg.cn/blog_migrate/c2330b31cbe7b958b175317bf49a8a40.png)

### 1、计算棒网络配置与网络共享配置

#### （1）计算棒网络配置

上位机使用OK3399-C Forlinx Desktop系统，点击右下角网络按钮选择弹出窗口中的“EditConnections...”选项：

![](https://i-blog.csdnimg.cn/blog_migrate/bc2ebf924c239117421d80b3066e7c9d.png)

选择计算棒usb网卡生成的有线网络节点：

![](https://i-blog.csdnimg.cn/blog_migrate/51d4d3216e5c12385971ee8e492781c8.png)

配置该节点为手动模式，设置IP：192.168.180.1，子网掩码：255.255.255.0，并保存：

![](https://i-blog.csdnimg.cn/blog_migrate/0dd24d3d772338e009fa060b2e8f5e03.png)

终端输入ifconfig指令查看网络节点配置如下，可见usb网卡配置完成：

![](https://i-blog.csdnimg.cn/blog_migrate/590d43fd5d1c704d6c22798179483c7d.png)

ping一下1808计算棒网络192.168.180.8，如下网络可以连通：

![](https://i-blog.csdnimg.cn/blog_migrate/f81d22cd00a4d13a9f83598168deb2ab.png)

使用ssh登录1808计算棒，用户名和密码默认都为toybrick，如下登陆成功：

![](https://i-blog.csdnimg.cn/blog_migrate/5dfa8500f79f55bd9d9179c97753c4c2.png)

#### （2）网络共享配置

运行ifconfig，可以看到eth0、wlan0等宿主机网卡，我们用于访问外网，enx10dcb69f022c为USB网卡（RK1808人工智能计算棒虚拟网卡）。不同的系统网卡名称可能不一样，以实际网卡名称为准。

![](https://i-blog.csdnimg.cn/blog_migrate/0b8495a81384fd5ea2954b01e5d1b63d.png)

首先配置宿主机网络，使宿主机可以连通以太网，这里我们使用wlan0节点来上网，具体配置不再赘述。

命令行执行如下命令，其中enx10dcb69f022c需要修改成用户本地实际值；正常情况只要设置一次即可，若拔插设备发现网卡名称改变了或者用户手动删除该网卡，则需要重新设置。

```cpp
 sudo nmcli connection add con-name toybrick type ethernet ifname enx10dcb69f022c autoconnect yes ip4 192.168.180.1/24
```

配置NAT功能，执行如下命令，其中eno1需要修改成用户本地实际值；关机失效，所以每次电脑重启都要重新设置。

```cpp
sudo sysctl   -w net.ipv4.ip_forward=1sudo iptable -Fsudo iptables -t nat -Fsudo  iptables  -t  nat  -A POSTROUTING -o wlan0 -j MASQUERADE
```

注意：以自己开发板联网的实际端口为准，例：eth0

iptables命令部分释义如下：

iptables --help

--flush -F [chain] Delete all rules in chain or all chains

--table -t table table to manipulate (default: `filter')

--append -A chain Append to chain

--jump -j target target for rule (may load target extension)

MASQUERAD，地址伪装，算是snat中的一种特例，可以实现自动化的snat

SNAT是source networkaddress translation的缩写，即源地址目标转换。比如，多个PC机使用ADSL路由器共享上网，每个PC机都配置了内网IP，PC机访问外部网络的时候，路由器将数据包的报头中的源地址替换成路由器的ip，当外部网络的服务器比如网站web服务器接到访问请求的时候，他的日志记录下来的是路由器的ip地址，而不是pc机的内网ip，这是因为，这个服务器收到的数据包的报头里边的“源地址”，已经被替换了，所以叫做SNAT，基于源地址的地址转换。

DNAT是destinationnet workaddress translation的缩写，即目标网络地址转换，典型的应用是，有个web服务器放在内网配置内网ip，前端有个防火墙配置公网ip，互联网上的访问者使用公网ip来访问这个网站，当访问的时候，客户端发出一个数据包，这个数据包的报头里边，目标地址写的是防火墙的公网ip，防火墙会把这个数据包的报头改写一次，将目标地址改写成web服务器的内网ip，然后再把这个数据包发送到内网的web服务器上，这样，数据包就穿透了防火墙，并从公网ip变成了一个对内网地址的访问了，即DNAT，基于目标的网络地址转换。

### 2、主动模式Mobilenet-ssd测试

#### （1）环境要求

1）参考“计算棒网络配置与网络共享配置”章节，完成RK1808人工智能计算棒网络配置(RNDIS)以及网络共享配置。

6. 宿主机需要插入USB摄像头，并连接显示器。
    

#### （2）部署计算棒程序

SSH方式

该方式通过ssh连接到RK1808人工智能计算棒，运行相应程序。

计算棒系统用户名：toybrick 密码：toybrick

计算棒系统用户名：root 密码：toybrick

建议用toybrick用户登录

1）使用官方链接下载Mobilenet-SSD主动模式demo软件包，解压，链接如下：

[https://eyun.baidu.com/s/3htJNFwS](https://eyun.baidu.com/s/3htJNFwS)

2）拷贝解压目录中的1808目录至计算棒

7. scp -r 1808/ [toybrick@192.168.180.8](mailto:toybrick@192.168.180.8):/home/toybrick/

3）ssh进入计算棒

8. ssh [toybrick@192.168.180.8](mailto:toybrick@192.168.180.8)

4）安装依赖包

9. sudo dnf install -y cmake make

5）编译

10. cd 1808/mkdir buildcd build/cmake ..make -j4

6）直接运行程序或设置程序为开机启动

•直接运行：

11. ./1808_ssd_demo

#### （3）部署上位机程序（以OK3399-Cdesktop为例）

1）安装依赖包make/cmake/opencv

12. sudo apt-get install -y make cmake libopencv-dev

2）进入Mobilenet-SSD主动模式demo软件包中的host目录，修改host/ssd_demo.cpp，根据开发板实际情况修改打开的摄像头节点：

13. cd host/

14. int main(void)

15. {

16. //ret = test.run(VIDEO_NODE, post_process, &data);

17. ret = test.run("/dev/video10", post_process, &data);

18. }

3）编译

19. mkdir buildcd build/cmake ..make -j4

4）计算棒程序运行起来后，运行上位机程序

20. ./ssd_demo

![](https://i-blog.csdnimg.cn/blog_migrate/436a9fe48fc04c6bd0aaf8de06a94069.png)

效果如下：

![](https://i-blog.csdnimg.cn/blog_migrate/2362b815d3afe63436ace85c7783188e.png)

### 3、主动模式yolov3测试

#### （1）环境要求

1）参考“计算棒网络配置与网络共享配置”章节，完成RK1808人工智能计算棒网络配置(RNDIS)以及网络共享配置。

2）OK3399-C开发板需要插入USB摄像头，并连接显示器。

#### （2）部署步骤

计算棒端：

1）使用官方链接下载示例源码master_yolov3.zip，解压，链接如下：

[https://eyun.baidu.com/s/3ekyvJS#sharelink/path=%2F](https://eyun.baidu.com/s/3ekyvJS#sharelink/path=%2F)

2）拷贝解压目录中的1808目录至计算棒：

scp -r 1808/ [toybrick@192.168.180.8](mailto:toybrick@192.168.180.8):/home/toybrick/

3）通过ssh连接到RK1808人工智能计算棒，运行yolov3master端程序

计算棒系统用户名toybrick 密码toybrick

计算棒系统用户名root 密码toybrick

建议用toybrick用户登录，安装python依赖包，root用户可能存在未知风险。

进入计算棒：

ssh [toybrick@192.168.180.8](mailto:toybrick@192.168.180.8)

4）安装依赖包：

sudodnf install python3-opencv -y

5）进入刚才拷贝的1808目录，运行1808端程序。

![](https://i-blog.csdnimg.cn/blog_migrate/862dfd15a184fd4eac165d31f5a015e9.png)

宿主机端：

1）安装依赖库

pip3 install --user numpy

sudo apt-get install -y python3-opencv

2）运行host端程序

![](https://i-blog.csdnimg.cn/blog_migrate/9957c4d27b1598b83c4b840fcedf237d.png)

#### （3）效果如下：

![](https://i-blog.csdnimg.cn/blog_migrate/5f82a3aecd02323192536a5838751126.png)

## 被 动 模 式

被动模式开发流程图如下：

![](https://i-blog.csdnimg.cn/blog_migrate/5797c48d6897254d09a8017cd0110842.png)

被动模式整体数据流程图如下：

![](https://i-blog.csdnimg.cn/blog_migrate/0c5a5caeb8e49ea9d70e5565e7250c3b.png)

### 1、被动模式Mobilenet-ssd测试

#### （1）使用官方链接下载被动模式Mobilenet-ssd源码

[http://t.rock-chips.com/wiki.php?mod=view&id=71](http://t.rock-chips.com/wiki.php?mod=view&id=71)

或者使用用户资料中提供的源码，目录为：用户资料\linux\源码\被动模式\Mobilenet-ssd\

#### （2）安装编译器、OpenCV、rknn-api

sudo apt-get install cmake gcc g++ //安装编译器

验证编译器已安装成功：

![](https://i-blog.csdnimg.cn/blog_migrate/bffaa9d54297dced103d1834bcb6f788.png)

sudo apt-get install libopencv-dev //安装opencv库文件

rknn-api 安装脚本在 slave_mobilenet_ssd 压缩包中

cd slave_mobilenet_ssd/install_rknn

sudo ./install_rknn_api.sh //安装rknn_api和通信程序

执行脚本后，下载了rknn_api和通信程序：

![](https://i-blog.csdnimg.cn/blog_migrate/d5c4d044ce08e092fb0ea7d7fbac94bb.png)

#### （3）代码编译运行

1）cd slave_mobilenet_ssd

修改ssd_demo.cpp文件中main函数中如下语句，根据开发板实际情况修改打开的摄像头节点

ret= test.run(VIDEO_NODE, post_process, &data);

改为：

ret= test.run("/dev/video10", post_process, &data);

2）mkdir build

3）cd build

4）cmake..

5）make

编译结果生成ssd_demo可执行程序：

![](https://i-blog.csdnimg.cn/blog_migrate/882e63d912d794f7e8aad34498075554.png)

6）npu_transfer_proxy& //启动NPU守护进程，通信代理服务。该程序由原厂提供。

![](https://i-blog.csdnimg.cn/blog_migrate/40fcd1f6ad7136cddc83f9283bf7a40b.png)

7）在PC上插入USB摄像头

8）在PC界面终端上执行./ssd_demo，将会在屏幕上显示SSD图像结果

![](https://i-blog.csdnimg.cn/blog_migrate/e41baad85806eacf0dc9967499a0b579.png)

![](https://i-blog.csdnimg.cn/blog_migrate/564f5b8eb1df516b7ac3158f67d786fb.png)

9）按'ESC'键退出运行

### 2、被动模式Rock-X测试

#### （1）使用原厂链接下载Rock-X SDK并解压，链接如下：

[https://eyun.baidu.com/s/3o9xqPPC#sharelink/path=%2F](https://eyun.baidu.com/s/3o9xqPPC#sharelink/path=%2F)

或者使用用户资料中提供的源码，目录为：用户资料\linux\源码\被动模式\Rock-X\

#### （2）安装编译器

sudo apt-get install cmake gcc g++

3、插入计算棒，等待上位机识别到计算棒

4、上位机运行rock-x依赖rknn_api, npu_transfer_proxy

用户可以先按照本文档第三章“被动模式Mobilenet-ssd测试”安装rknn_api；用户也可以通过原厂提供的链接地址直接下载rknn_api, npu_transfer_proxy，如下：

[http://repo.rock-chips.com/rk1808/rknn-api/](http://repo.rock-chips.com/rk1808/rknn-api/)

[http://repo.rock-chips.com/rk1808/npu_transfer_proxy/](http://repo.rock-chips.com/rk1808/npu_transfer_proxy/)

5、运行npu_transfer_proxy和计算棒进行通信

npu_transfer_proxy &

6、编译测试用demo

cd demo/command_line_demo

./build-linux-rk3399pro-on-device.sh

此时会编译得到rock-x中demo目录下的各用例并存放在install目录下

![](https://i-blog.csdnimg.cn/blog_migrate/d2360d2c5691215dfdbde9c7f2d53d14.png)

7、测试生成的用例中的rockx_face_landmark_demo

cd install/rockx_linux_rk3399pro/rockx_face_landmark_demo/

export LD_LIBRARY_PATH=../lib

./rockx_face_landmark face4.jpg 68 //人脸特征点定位（68点）

8、测试效果如下：

![](https://i-blog.csdnimg.cn/blog_migrate/c8caa1558dc814ffc03ae52ce9098c59.png)

9、Rock-X command_line_demo提供的例程

rockx_carplate_demo 车牌识别

rockx_face_attribute_demo 人脸属性识别（性别、年龄）

rockx_face_detection_demo 人脸检测

rockx_face_landmark_demo 人脸特征点定位

rockx_head_detection_demo 人头检测

rockx_object_detection_demo 物体检测

rockx_object_track_demo 物体运动检测

rockx_pose_body_demo 人体姿态检测

rockx_pose_finger_demo 手掌节点姿态检测

rockx_face_liveness_demo 活体检测

rockx_face_recognition_demo 人脸识别对比

### 3、被动模式yolov3测试

注意该测试中安装的部分包因为资源问题下载可能会因超时而无法下载，遇到这种情况，可以使用我司提供的现成的安装包，目录为：用户资料\ linux\源码\被动模式\yolov3 demo\安装包\

#### （1）安装python3.5

ubuntu18.04默认python3.6，该版本部分库没有资源无法安装，所以更换为python3.5

sudo apt-get update

sudo apt-get install software-properties-common

sudo add-apt-repository ppa:deadsnakes/ppa

sudo apt-get update

sudo apt-get install python3.5-dev

sudo apt-get --reinstall install python3.5-minimal

sudo mv /usr/bin/python3 /usr/bin/python3-old

sudo ln -s /usr/bin/python3.5 /usr/bin/python3

sudo update-alternatives --install /usr/bin/python python/usr/bin/python3.5 300

验证python3.5是否安装成功并且python3已经修改为默认使用3.5：

![](https://i-blog.csdnimg.cn/blog_migrate/cdac046bc9536c073bc9b4aceb4ffcdf.png)

安装新版pip：

wget [https://bootstrap.pypa.io/get-pip.py](https://bootstrap.pypa.io/get-pip.py)

sudo python3 get-pip.py

sudo pip3 install setuptools --upgrade

sudo ln -s /usr/local/bin/pip3 /usr/bin/pip3

验证pip安装成功且默认使用python3.5的pip工具：

![](https://i-blog.csdnimg.cn/blog_migrate/26b3f6debe2961d04955ab09c224ded6.png)

#### （2）安装依赖库

sudo apt-get install cmake gcc g++ libprotobuf-dev protobuf-compiler

sudo apt-get install liblapack-dev libjpeg-dev zlib1g-dev

sudo apt-get install python3-dev python3-pip python3-scipy

sudo apt-get install python3-opencv python3-numpy python3-lmd bpython3-h5py

pip3 install wheel setuptools

sudo apt-get build-dep python3-h5py && pip3 install h5py

pip3 install --user scipy

pip3 install --user grpcio==1.26.0

pip3 install --user onnx

pip3 uninstall pillow

pip3 install --user pillow==4.2.1

pip3 uninstall h5py

pip3 install --user h5py==2.8.0rc1

注意部分安装包因为资源问题下载可能会因超时而无法下载，可以使用我司提供的现成的安装包。

查看上述指令安装的包是否安装到python3.5目录下：

![](https://i-blog.csdnimg.cn/blog_migrate/cc82aebe14096469a03738d14cf46409.png)

#### （3）安装TensorFlow

wget [http://repo.rock-chips.com/python/tensorflow-1.11.0-cp35-none-linux_aarch64.whl](http://repo.rock-chips.com/python/tensorflow-1.11.0-cp35-none-linux_aarch64.whl)

pip3 install --user tensorflow-1.11.0-cp35-none-linux_aarch64.whl

TensorFlow也可以到/home/forlinx/.local/lib/python3.5/site-packages/目录下查看安装情况

#### （4）Python3.5安装OpenCV3

1）下载opencv和opencv_contrib，这两部分代码下载也比较困难，建议使用我司用户资料中提供的源码包，目录为：用户资料\linux\源码\被动模式\yolov3demo\安装包\：

cd~

git clone [https://github.com/opencv/opencv.git](https://github.com/opencv/opencv.git)

git clone [https://github.com/opencv/opencv_contrib.git](https://github.com/opencv/opencv_contrib.git)

2）编译opencv源码

cd~/opencv

mkdir build

cd build

cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -DWITH_TBB=ON -D BUILD_NEW_PYTHON_SUPPORT=ON -D WITH_V4L=ON -DINSTALL_C_EXAMPLES=ON -D INSTALL_PYTHON_EXAMPLES=ON -DBUILD_EXAMPLES=ON -D WITH_QT=ON -D WITH_GTK=ON -D WITH_OPENGL=ON ..

make

编译结果如下：

![](https://i-blog.csdnimg.cn/blog_migrate/e43f280fccae22221926419199bc4da5.png)

3）安装OpenCV

sudo make install

部分安装信息：

![](https://i-blog.csdnimg.cn/blog_migrate/d2f9e52088591eb9ecdeb13b84609684.png)

OpenCV的安装文件也可以在系统中找到，例如：

/usr/local/lib/libopencv_core.so.4.3.0

/usr/local/include/opencv4/opencv2/cvconfig.h

编译时会有报错解决方法可以参考如下链接：

[https://stackoverflow.com/questions/28776053/opencv-gtk2-x-error](https://stackoverflow.com/questions/28776053/opencv-gtk2-x-error)

[http://www.luyixian.cn/news_show_316237.aspx](https://stackoverflow.com/questions/28776053/opencv-gtk2-x-error)

或者可以使用我司提供的现成的OpenCV的源码。

#### （5）安装rknn-toolkit

wget [http://repo.rock-chips.com/python/tensorflow-1.11.0-cp35-none-linux_aarch64.whl](http://repo.rock-chips.com/python/tensorflow-1.11.0-cp35-none-linux_aarch64.whl)

pip3 --default-timeout=100000 install --user rknn_toolkit-1.1.0-cp35-cp35m-linux_aarch64.whl

rknn_toolkit也可以到/home/forlinx/.local/lib/python3.5/site-packages/目录下查看安装情况，可以看到对应安装目录：

![](https://i-blog.csdnimg.cn/blog_migrate/1fa2b52c3fd921a57c02abd5a4b9e856.png)

#### （6）下载yolov3 demo程序测试运行

wget -r -np -nc -nH [http://repo.rock-chips.com/rk1808/yolov3/](http://repo.rock-chips.com/rk1808/yolov3/)

cd rk1808/yolov3/

修改rknn_camera_tiny_multiProcess.py中打开的摄像头节点：

video= cv2.VideoCapture(0)

改为：

video= cv2.VideoCapture("/dev/video10")

注意：摄像头节点需要依据自己开发板的实际情况来修改

命令行执行：

python3.5 rknn_camera_tiny_multiProcess.py

运行结果如下：

![](https://i-blog.csdnimg.cn/blog_migrate/c5d494f3ba39f20d1b9f7afb0f558cd0.png)

至此，OK3399-C开发板+RK1808人工智能计算棒在主动模式和被动模式下的测评就告一段落。