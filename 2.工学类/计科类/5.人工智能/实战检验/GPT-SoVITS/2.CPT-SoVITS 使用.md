# **一、切割音频**

## 1.ob-语音切分工具-输入原声路径

![](https://i0.hdslb.com/bfs/note/47fb66d768efd1d86df1c86bf428c15659a2730d.png@408w_!web-note.webp)

## 2.ob-语音切分工具-输出原声路径

![](https://i0.hdslb.com/bfs/note/9c73fcefb9f911c87ec1f157e645285a6a031038.png@386w_!web-note.webp)

## 3.开始切割

![](https://i0.hdslb.com/bfs/note/98540a65ab5b2cd42eeeb45ef4f49c309c8c2dcf.png@470w_!web-note.webp)

## 4.成功

![](https://i0.hdslb.com/bfs/note/61d261960c6e9934f9f8e1a0ae1bdbb060ffbc88.png@540w_!web-note.webp)

## 5.检查
检查切割好的文件，要求每个音频文件不超过20s

# **二、打标**

## 1.0c中文批量离线ASR工具
### 1. 输入切割音频路径

![](https://i0.hdslb.com/bfs/note/22c752e295595b0f3be273eb5240e3055ec39a7b.png@568w_!web-note.webp)

## 2.输出文本路径

![](https://i0.hdslb.com/bfs/note/0319e32b5f1a8b481165d05fb0d3b280aa9a6090.png@582w_!web-note.webp)

## 3.开始离线批量ASR

![](https://i0.hdslb.com/bfs/note/5b4d16f37af4ddecbdcb391ebb372e804bd1f087.png@396w_!web-note.webp)

>**提示**：此步没有完成会显示正在进行任务...，不要误认为没有反应了

## 4.完成

![](https://i0.hdslb.com/bfs/note/4dc96e904b303dc6fa4667630647dd936b2ec5d2.png@538w_!web-note.webp)

# **三、矫正**

## 1.0d-语音文本校对标注工具-复制文本路径

![](https://i0.hdslb.com/bfs/note/34442c50815c0ba6ffd4e055a693330310dfc896.png@690w_!web-note.webp)

  

![](https://i0.hdslb.com/bfs/note/7aead00a5cc4aeec7d46b1265d9925fe7b5afea8.png@690w_!web-note.webp)

>注意：一定要是文件的路径，不要是文件夹的路径，否则会终端显示类似如下的报错，实际上就是以打开文件的方式打开文件夹造成的

```bash
错误: 没有找到进程 "11568"。
"E:\TestProject\GPT-SoVITS-beta0706\runtime\python.exe" tools/subfix_webui.py --load_list "E:\TestProject\GPT-SoVITS-beta0706\DATA\Own\asr_opt" --webui_port 9871 --is_share False
Traceback (most recent call last):
  File "E:\TestProject\GPT-SoVITS-beta0706\tools\subfix_webui.py", line 310, in <module>
    set_global(args.load_json, args.load_list, args.json_key_text, args.json_key_path, args.g_batch)
  File "E:\TestProject\GPT-SoVITS-beta0706\tools\subfix_webui.py", line 295, in set_global
    b_load_file()
  File "E:\TestProject\GPT-SoVITS-beta0706\tools\subfix_webui.py", line 274, in b_load_file
    b_load_list()
  File "E:\TestProject\GPT-SoVITS-beta0706\tools\subfix_webui.py", line 244, in b_load_list
    with open(g_load_file, 'r', encoding="utf-8") as source:
PermissionError: [Errno 13] Permission denied: 'E:\\TestProject\\GPT-SoVITS-beta0706\\DATA\\Own\\asr_opt'
```


## 2.勾选-是否开启打标WebUI-页面跳转

![](https://i0.hdslb.com/bfs/note/f4aa980ad69d8721eb143be7ea728580292d7f3b.png@502w_!web-note.webp)

## 3.矫正文本

![](https://i0.hdslb.com/bfs/note/7a0d3a4cc602c9ac9c9f8b7b6b699d9de99dad55.png@690w_!web-note.webp)

## 4.改完保存，文字比较多再点Next Index

![](https://i0.hdslb.com/bfs/note/dcca4fb383c5b31fd3d7bb358636d3eba2352d2e.png@406w_!web-note.webp)

## 5.点保存文件-Save File

![1736328370201.png](https://www.helloimg.com/i/2025/01/08/677e4417c497a.png)


>**注意**：保存是修改原载入文件进行保存，而不是创建一个新文件

## 6.关闭网页-取消勾选“打标WsbUI”

![](https://i0.hdslb.com/bfs/note/da857f0a42b19e3233fc550bac096c6db80f0a00.png@418w_!web-note.webp)

  

# **四、切换到-1-GTP-SoVITS-TTS**

## **1A-训练级格式化工具**

### 1. 填写实验/模型名
![](https://i0.hdslb.com/bfs/note/19e49d6b39674a3627123b2c0f969e66665ace16.png@690w_!web-note.webp)

### 2. 添加标注文件路径
![](https://i0.hdslb.com/bfs/note/7862e0fe59b6133f7214abb869b62c5e3c84c22b.png@690w_!web-note.webp)


### 3. 添加分割音频目录路径

![](https://i0.hdslb.com/bfs/note/7862e0fe59b6133f7214abb869b62c5e3c84c22b.png@690w_!web-note.webp)

>**注意**：标准脚本路径记得去双引号“”

### 4.点击一键三连

![](https://i0.hdslb.com/bfs/note/bb9b1590681e6016f6a440290a5c61f7e793c707.png@690w_!web-note.webp)


成功

![](https://i0.hdslb.com/bfs/note/dbf7b1bf0af60fb69e9f086cfbcb57b9489d2fae.png@398w_!web-note.webp)


![1736329155594.png](https://www.helloimg.com/i/2025/01/08/677e472b82028.png)
<center>图：成功后的终端输出</center>


## **1B-微调训练**

### 1.分别训练-成后下一步

![](https://i0.hdslb.com/bfs/note/aabd0d18da5f6a0181548ab365d13d51b83dd929.png@690w_!web-note.webp)






---


- 问题描述：SoVITS训练终端报错
```bash
-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "E:\TestProject\GPT-SoVITS-beta0706\runtime\lib\site-packages\torch\multiprocessing\spawn.py", line 69, in _wrap
    fn(i, *args)
  File "E:\TestProject\GPT-SoVITS-beta0706\GPT_SoVITS\s2_train.py", line 254, in run
    train_and_evaluate(
  File "E:\TestProject\GPT-SoVITS-beta0706\GPT_SoVITS\s2_train.py", line 352, in train_and_evaluate
    y_hat_mel = mel_spectrogram_torch(
  File "E:\TestProject\GPT-SoVITS-beta0706\GPT_SoVITS\module\mel_processing.py", line 135, in mel_spectrogram_torch
    spec = torch.stft(
  File "E:\TestProject\GPT-SoVITS-beta0706\runtime\lib\site-packages\torch\functional.py", line 641, in stft
    return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]
RuntimeError: cuFFT doesn't support signals of half type with compute capability less than SM_53, but the device containing input half tensor only has SM_52
```
- 问题分析：
	这是由于半精度 cuFFT 需要 GPU 架构至少是 SM_53 以上，而我的GPU是TITAN X，只支持SM_52
- 问题诊断：
	SoVITS的JSON配置中开启了对于半精度cuFFT的支持，但是你的GPU又不支持
- 方案尝试：
	修改`GPT-SoVITS-beta0706\GPT_SoVITS\configs\s2json`将其中的`"fp16_run": true,`的`true`修改为`false`后并保存
- 方案检验：
	终端能够正常跑动模型
```bash
INFO:mine:[2.5445058345794678, 4.0188374519348145, 9.532323837280273, 19.340923309326172, 0.0, 2.7108802795410156, 0, 9.99875e-05]
100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:41<00:00,  2.46s/it]
INFO:mine:====> Epoch: 1
100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:29<00:00,  1.71s/it]
INFO:mine:====> Epoch: 2
100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:28<00:00,  1.67s/it]
INFO:mine:====> Epoch: 3
100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:28<00:00,  1.66s/it]
INFO:mine:Saving model and optimizer state at iteration 4 to logs/mine/logs_s2\G_233333333333.pth
INFO:mine:Saving model and optimizer state at iteration 4 to logs/mine/logs_s2\D_233333333333.pth
INFO:mine:saving ckpt mine_e4:Success.
INFO:mine:====> Epoch: 4
100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:28<00:00,  1.69s/it]
INFO:mine:====> Epoch: 5
 88%|████████████████████████████████████████████████████████████████████████▎         | 15/17 [00:25<00:03,  1.53s/it]INFO:mine:Train Epoch: 6 [88%]
INFO:mine:[2.229780435562134, 2.6936821937561035, 8.767420768737793, 14.989115715026855, 0.0, 0.5111721158027649, 100, 9.99250234335941e-05]
100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:29<00:00,  1.74s/it]
INFO:mine:====> Epoch: 6
100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:28<00:00,  1.70s/it]
INFO:mine:====> Epoch: 7
100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:29<00:00,  1.75s/it]
INFO:mine:Saving model and optimizer state at iteration 8 to logs/mine/logs_s2\G_233333333333.pth
INFO:mine:Saving model and optimizer state at iteration 8 to logs/mine/logs_s2\D_233333333333.pth
INFO:mine:saving ckpt mine_e8:Success.
INFO:mine:====> Epoch: 8
```



```ad-note
title:扩展：内部架构代号ＳＭ
### SM_53的背景

- **SM_5x系列**：SM_5x系列的架构代号通常用于Maxwell架构的GPU。Maxwell是NVIDIA在2014年到2015年间推出的一代GPU架构，主要用于桌面和移动设备。
- **具体版本**：
    - **SM_50**：通常用于桌面级GPU，如GTX 750 Ti。
    - **SM_52**：用于一些桌面级和移动级GPU，如GTX 960。
    - **SM_53**：用于一些更高端的桌面级GPU，如GTX 980。

### 计算能力（Compute Capability）

- **计算能力**：这是NVIDIA用来描述其GPU架构的一个指标，主要用于CUDA编程环境。计算能力越高，通常意味着GPU支持更多的功能和更高的性能。
- **兼容性**：不同的计算能力对应不同的CUDA版本和功能支持。例如，某些深度学习库或算法可能需要更高版本的计算能力才能运行。

### 实际应用

- **选择GPU**：在选择GPU时，了解其计算能力是非常重要的，尤其是在进行深度学习或其他需要高性能计算的应用时。
- **代码优化**：了解GPU的计算能力可以帮助开发者更好地优化代码，利用GPU的特性来提高性能。

总之，SM_53确实是NVIDIA的一个架构代号，用于表示特定的计算能力和硬件特性。
```



### 2.推理

![](https://i0.hdslb.com/bfs/note/a897093bd3fb76a93efd6df6f2550779dfbd16d7.png@690w_!web-note.webp)

>**步骤**：依次点击1C-推理->刷新模型路径->GPT模型列表->SoVITS模型列表->勾选开启WebUI

### 3.配置选项


![](https://i0.hdslb.com/bfs/note/dbacb36e45cda7f86b32f76659faaac5a0ec795b.png@690w_!web-note.webp)

- 拖入参考音频：
	此步可以使用前面你切片切出来的音频

- 参考音频文本：
	你使用的参考音频的文字信息，
